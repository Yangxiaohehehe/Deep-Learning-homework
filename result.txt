五个改进点：
1. 宽度深度
2. 残差
3. 注意力
4. 参数 优化器 学习率
5. 数据增强的方法

C:数据集


1. 最初的结果：0.225 86.32%	number of parameters: 7.28M


-----------------------------------------------------------------------------------------------------------------------------------

2. Adam->AdamW  batch：64->128  85.9 0.141



-----------------------------------------------------------------------------------------------------------------------------------


3. 网络更宽或更深  多加一层512 512和开始多一层3->64   重新计算输出维度  0.402	85.56%
---

新增了损失绘制过程

3.1 只多开始的一层  85.60%  7.35M



3.2 多开始一层 结尾也多一层 
batch128
number of parameters: 7.36M  84.51%

调高dropout 0.3-0.4 0.5-0.6 收敛速度会满  7.36M  84.51%  
正常drop:  85%

调回dropout 调低学习率 drop只改动了一个 0.3-0.4 第一层 : 82.66%0.869





3.3 改宽、深一点：
多加两层 中间  512-1024-1024两层
学习率1e-4 128batch
number of parameters: 14.36M
84.69%  0.049 
过拟合






4 残差
8.14M
学习率1e-4 128 


















