{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "This code baseline is inspired by and modified from [this great tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).\n",
    "\n",
    "This code can achieve an accuracy of approximately 86.50% on CIFAR-10. Please set up the environment and run your experiments starting from this baseline. You are expected to achieve an accuracy higher than this baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import some necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as tv_datasets\n",
    "import torchvision.transforms as tv_transforms\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差结构\n",
    "class Resblock(nn.Module):\n",
    "  def __init__(self,in_channel,out_channel,downsample=False):\n",
    "    super().__init__()\n",
    "    self.in_channel = in_channel\n",
    "    self.out_channel = out_channel\n",
    "    self.downsample = downsample\n",
    "    strides = 2 if self.downsample else 1\n",
    "    if self.downsample or in_channel!=out_channel:\n",
    "      self.conv3 = nn.Conv2d(in_channel,out_channel,kernel_size=1,stride=strides,padding=0,bias=False)\n",
    "\n",
    "    self.conv1 = nn.Conv2d(in_channel,out_channel,kernel_size=3,stride =strides,padding =1,bias=False)\n",
    "    self.bn1  = nn.BatchNorm2d(out_channel)\n",
    "    self.relu1 = nn.ReLU(inplace = True)\n",
    "    self.bn2  = nn.BatchNorm2d(out_channel)\n",
    "    self.conv2 = nn.Conv2d(out_channel,out_channel,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "    self.relu2 = nn.ReLU(inplace = True)\n",
    "\n",
    "  def forward(self,x):\n",
    "    identity = x\n",
    "    Y = self.relu1(self.bn1(self.conv1(x)))\n",
    "    Y = self.bn2(self.conv2(Y))\n",
    "    if self.downsample or self.in_channel!=self.out_channel:\n",
    "      identity = self.conv3(identity)\n",
    "    Y=Y+identity\n",
    "    return self.relu2(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        # Squeeze: 全局平均池化，将 [B, C, H, W] -> [B, C, 1, 1]\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # Excitation: 两个全连接层\n",
    "        self.excitation = nn.Sequential(\n",
    "            # 第一个FC层，将通道数 C 压缩到 C / r\n",
    "            nn.Linear(in_channels, in_channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # 第二个FC层，将通道数恢复到 C\n",
    "            nn.Linear(in_channels // reduction_ratio, in_channels, bias=False),\n",
    "            nn.Sigmoid() # 使用 Sigmoid 得到 0-1 之间的权重\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        # y: [B, C, 1, 1] -> [B, C]\n",
    "        y = self.squeeze(x).view(b, c)\n",
    "        # y: [B, C] -> [B, C] (通道权重) -> [B, C, 1, 1]\n",
    "        y = self.excitation(y).view(b, c, 1, 1)\n",
    "\n",
    "        # Rescale: 将学习到的通道权重乘以原始输入特征图\n",
    "        return x * y.expand_as(x)\n",
    "# 放在你的 SEBlock 定义的旁边即可\n",
    "class ChannelAttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(ChannelAttentionModule, self).__init__()\n",
    "        # 使用一个共享的全连接网络\n",
    "        self.shared_mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels // reduction_ratio, in_channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "\n",
    "        # 平均池化分支\n",
    "        avg_out = self.shared_mlp(torch.mean(x, dim=[2, 3])).view(b, c, 1, 1)\n",
    "\n",
    "        # 最大池化分支\n",
    "        max_out = self.shared_mlp(torch.max(x, dim=3)[0].max(dim=2)[0]).view(b, c, 1, 1)\n",
    "\n",
    "        # 将两个分支的输出相加，然后通过sigmoid得到权重\n",
    "        channel_weights = self.sigmoid(avg_out + max_out)\n",
    "\n",
    "        # 将权重乘回原输入\n",
    "        return x * channel_weights\n",
    "class SpatialAttentionModule(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttentionModule, self).__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Keep a reference to the original input tensor\n",
    "        original_input = x\n",
    "\n",
    "        # Perform pooling across the channel dimension\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "\n",
    "        # Concatenate to create a 2-channel tensor\n",
    "        concatenated = torch.cat([avg_out, max_out], dim=1)\n",
    "\n",
    "        # Generate the spatial attention map (a 1-channel tensor of weights)\n",
    "        spatial_weights = self.conv(concatenated)\n",
    "        spatial_weights = self.sigmoid(spatial_weights)\n",
    "\n",
    "        # Multiply the ORIGINAL input by the learned weights.\n",
    "        # This is the corrected step!\n",
    "        return original_input * spatial_weights\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttentionModule(in_channels, reduction_ratio)\n",
    "        self.spatial_attention = SpatialAttentionModule(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 先应用通道注意力\n",
    "        x = self.channel_attention(x)\n",
    "        # 再应用空间注意力\n",
    "        x = self.spatial_attention(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some experimental setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_epochs = 128\n",
    "batch_size = 128\n",
    "num_workers = 2\n",
    "print_every = 200\n",
    "\n",
    "optim_name = \"Adam\"\n",
    "optim_kwargs = dict(\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-6,\n",
    ")\n",
    "\n",
    "# optim_name = \"SGD\"\n",
    "# optim_kwargs = dict(\n",
    "#     lr=0.005,\n",
    "#     momentum=0.9,\n",
    "#     weight_decay=5e-4,\n",
    "# )\n",
    "\n",
    "\n",
    "# optim_name = \"AdamW\"\n",
    "# optim_kwargs = dict(\n",
    "#     lr=3e-4,         \n",
    "#     weight_decay=1e-2, \n",
    "# )\n",
    "\n",
    "# preprocessing pipeline for input images\n",
    "transformation = dict()\n",
    "for data_type in (\"train\", \"test\"):\n",
    "    is_train = data_type==\"train\"\n",
    "    transformation[data_type] = tv_transforms.Compose(([\n",
    "        tv_transforms.RandomRotation(degrees=15),\n",
    "        tv_transforms.RandomHorizontalFlip(),\n",
    "        tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    ] if is_train else []) + \n",
    "    [\n",
    "        tv_transforms.ToTensor(),\n",
    "        tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "for data_type in (\"train\", \"test\"):\n",
    "    is_train = data_type==\"train\"\n",
    "    \n",
    "    if is_train:\n",
    "        # 这是新的训练集增强管道\n",
    "        transformation[data_type] = tv_transforms.Compose([\n",
    "            # 1. 首先应用 TrivialAugmentWide\n",
    "            tv_transforms.TrivialAugmentWide(),\n",
    "            tv_transforms.RandomRotation(degrees=15),\n",
    "            # 2. 接着，仍然保留最核心的几何变换\n",
    "            tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            tv_transforms.RandomHorizontalFlip(),\n",
    "            \n",
    "            # 3. 转换为 Tensor\n",
    "            tv_transforms.ToTensor(),\n",
    "            \n",
    "            # 4. 归一化\n",
    "            tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "            \n",
    "            # 5. 【推荐】最后，可以再添加一个 RandomErasing\n",
    "            # TrivialAugment 和 Erasing 组合使用效果很好\n",
    "            tv_transforms.RandomErasing(p=0.25, scale=(0.02, 0.2)),\n",
    "        ])\n",
    "    else:\n",
    "        # 测试集保持不变\n",
    "        transformation[data_type] = tv_transforms.Compose([\n",
    "            tv_transforms.ToTensor(),\n",
    "            tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare datasets\n",
    "dataset, loader = {}, {}\n",
    "for data_type in (\"train\", \"test\"):\n",
    "    is_train = data_type==\"train\"\n",
    "    dataset[data_type] = tv_datasets.CIFAR10(\n",
    "        root=\"./data\", train=is_train, download=True, transform=transformation[data_type],\n",
    "    )\n",
    "    loader[data_type] = torch.utils.data.DataLoader(\n",
    "        dataset[data_type], batch_size=batch_size, shuffle=is_train, num_workers=num_workers,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 深  宽\n",
    "\n",
    "net = nn.Sequential(\n",
    "    # Block 1: Input (3, 32, 32) -> Output (64, 16, 16)\n",
    "    nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Block 2: Input (64, 16, 16) -> Output (128, 8, 8)\n",
    "    nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Block 3: Input (128, 8, 8) -> Output (256, 4, 4)\n",
    "    nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Block 4: Input (256, 4, 4) -> Output (512, 2, 2)\n",
    "    nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Flatten\n",
    "    nn.Flatten(),\n",
    "\n",
    "    # Classifier\n",
    "    nn.Linear(512 * 2 * 2, 4096),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(4096, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augumentation\n",
    "import numpy as np\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    \"\"\"\n",
    "    生成随机的裁切框 (bounding box)\n",
    "    \"\"\"\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    # 根据 lambda 计算裁切区域的宽高\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # 随机选择裁切区域的中心点\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    # 确定裁切区域的四个坐标点，并确保它们在图像范围内\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    \"\"\"\n",
    "    对一个批次的数据应用 CutMix\n",
    "\n",
    "    参数:\n",
    "    - x: 输入图像批次 (Tensor)\n",
    "    - y: 对应的标签批次 (Tensor)\n",
    "    - alpha: Beta 分布的参数，控制混合比例，alpha=1.0 通常是个不错的选择\n",
    "\n",
    "    返回:\n",
    "    - mixed_x: 经过 CutMix 处理的图像批次\n",
    "    - y_a, y_b: 参与混合的两个原始标签\n",
    "    - lam: 混合比例\n",
    "    \"\"\"\n",
    "    # 从 Beta 分布中采样混合比例 lambda\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    # 生成一个随机的索引，用于从批次中选择另一张图片进行混合\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "\n",
    "    # 获取参与混合的两个原始标签\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    # 生成裁切框\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "\n",
    "    # 将第二张图的裁切区域粘贴到第一张图上\n",
    "    x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n",
    "\n",
    "    # 根据裁切区域的实际大小，调整混合比例 lambda\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "\n",
    "    return x, y_a, y_b, lam\n",
    "def cutmix_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"\n",
    "    计算 CutMix 的损失\n",
    "    criterion: 原始的损失函数 (例如 nn.CrossEntropyLoss)\n",
    "    pred: 模型的预测输出\n",
    "    y_a, y_b: 参与混合的两个原始标签\n",
    "    lam: 混合比例\n",
    "    \"\"\"\n",
    "    loss_a = criterion(pred, y_a)\n",
    "    loss_b = criterion(pred, y_b)\n",
    "    return lam * loss_a + (1 - lam) * loss_b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention\n",
    "# class NetWithAttention(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NetWithAttention, self).__init__()\n",
    "\n",
    "#         # 将卷积层分解成更小的块，方便插入注意力\n",
    "#         self.conv_block1 = nn.Sequential(\n",
    "#             nn.Conv2d(3, 128, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3)\n",
    "#         )\n",
    "#         self.conv_block2 = nn.Sequential(\n",
    "#             nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3)\n",
    "#         )\n",
    "#         self.conv_block3 = nn.Sequential(\n",
    "#             nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True)\n",
    "#             # 在这里，我们准备插入SE模块\n",
    "#         )\n",
    "\n",
    "#         # --- 在这里定义我们的SE模块 ---\n",
    "#         # 输入通道数是 512，因为 conv_block3 的输出通道是 512\n",
    "#         self.attention = SEBlock(in_channels=512)\n",
    "\n",
    "#         self.conv_block4 = nn.Sequential(\n",
    "#             nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3)\n",
    "#         )\n",
    "\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(256 * 4 * 4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "#             nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "#             nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "#             nn.Linear(128, 10),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # 定义新的数据流\n",
    "#         x = self.conv_block1(x)\n",
    "#         x = self.conv_block2(x)\n",
    "#         x = self.conv_block3(x)\n",
    "\n",
    "#         # --- 在数据流中应用注意力 ---\n",
    "#         x = self.attention(x)\n",
    "\n",
    "#         x = self.conv_block4(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "class NetWithMultipleCBAM(nn.Module):\n",
    "    def __init__(self, num_classes=10): # 添加 num_classes 参数以增加灵活性\n",
    "        super(NetWithMultipleCBAM, self).__init__()\n",
    "\n",
    "        # --- 第1个卷积块 ---\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128), # 推荐在ReLU前加入BN层，可以稳定训练\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.attention1 = CBAM(in_channels=128)\n",
    "\n",
    "        # --- 第2个卷积块 ---\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.attention2 = CBAM(in_channels=256)\n",
    "\n",
    "        # --- 第3个卷积块 ---\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.attention3 = CBAM(in_channels=512)\n",
    "\n",
    "        # --- 第4个卷积块 ---\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.attention4 = CBAM(in_channels=256)\n",
    "\n",
    "        # --- 分类器 ---\n",
    "        # 输入尺寸需要根据你的输入图像大小计算。\n",
    "        # CIFAR-10 (32x32): 32 -> MaxPool -> 16 -> MaxPool -> 8 -> MaxPool -> 4. 所以是 256 * 4 * 4\n",
    "        # Tiny-ImageNet (64x64): 64 -> 32 -> 16 -> 8. 所以是 256 * 8 * 8\n",
    "        # 这里以CIFAR-10为例\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 4 * 4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.attention1(x)\n",
    "\n",
    "        # Block 2\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.attention2(x)\n",
    "\n",
    "        # Block 3\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.attention3(x)\n",
    "\n",
    "        # Block 4\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.attention4(x)\n",
    "\n",
    "        # Flatten and Classify\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差\n",
    "# class CIFAR_Net_With_Resblock(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # --- 1. 初始卷积和下采样部分 (对应你原来的前两个卷积块) ---\n",
    "#         self.stem = nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "\n",
    "#         self.layer1 = Resblock(in_channel=64,  out_channel=128, downsample=True)\n",
    "#         self.layer2 = Resblock(in_channel=128,  out_channel=128, downsample=False)\n",
    "#         # 128x16x16 -> 256x8x8\n",
    "#         self.layer3 = Resblock(in_channel=128, out_channel=256, downsample=True)\n",
    "#         self.layer4 = Resblock(in_channel=256, out_channel=256, downsample=False)\n",
    "#         # 256x8x8 -> 512x4x4\n",
    "#         self.layer5 = Resblock(in_channel=256, out_channel=512, downsample=True)\n",
    "#         # 为了增加网络深度，可以再加一个普通的Resblock\n",
    "#         # 512x4x4 -> 512x4x4\n",
    "#         self.layer6 = Resblock(in_channel=512, out_channel=512)\n",
    "\n",
    "#         # --- 3. 全局池化和分类器 ---\n",
    "#         self.final_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Flatten(),\n",
    "#             # 注意：这里的输入维度是最后一个残差块的输出通道数 (512)\n",
    "#             nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.4),\n",
    "#             nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.4),\n",
    "#             nn.Linear(128, 10)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.stem(x)\n",
    "\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = self.layer4(x)\n",
    "#         x = self.layer5(x)\n",
    "#         x = self.layer6(x)\n",
    "\n",
    "#         x = self.final_pool(x)\n",
    "#         x = self.classifier(x)\n",
    "\n",
    "#         return x\n",
    "# net = CIFAR_Net_With_Resblock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# our network architecture\n",
    "# net = nn.Sequential(\n",
    "#     nn.Conv2d(3, 128, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "#     nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "#     nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "#     nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "#     nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(256 * 4 * 4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "#     nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "#     nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "#     nn.Linear(128, 10),\n",
    "# )\n",
    "\n",
    "# move to device\n",
    "net.to(device)\n",
    "\n",
    "# print the number of parameters\n",
    "print(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the network optimizer\n",
    "optimizer = getattr(optim, optim_name)(net.parameters(), **optim_kwargs)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# add\n",
    "loss_history = []\n",
    "iter_history = []\n",
    "current_iter = 0\n",
    "val_loss_history = []\n",
    "val_acc_history = []\n",
    "val_iter_history = [] \n",
    "\n",
    "# training loop\n",
    "net.train()\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (img, target) in enumerate(loader[\"train\"]):\n",
    "        img, target = img.to(device), target.to(device)\n",
    "\n",
    "        pred = net(img)\n",
    "        loss = criterion(pred, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        current_iter += 1 # 迭代计数器\n",
    "        if i % print_every == print_every - 1:\n",
    "            avg_loss = running_loss / print_every\n",
    "            print(f\"[epoch={epoch + 1:3d}, iter={i + 1:5d}] loss: {running_loss / print_every:.3f}\")\n",
    "            # <-- 修改点: 记录当前迭代次数和对应的平均loss -->\n",
    "            iter_history.append(current_iter)\n",
    "            loss_history.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    # <-- MODIFICATION: Initialize correct and total counters -->\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for img, target in loader[\"test\"]:\n",
    "            img, target = img.to(device), target.to(device)\n",
    "            pred = net(img)\n",
    "            loss = criterion(pred, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # <-- MODIFICATION: Add the accuracy calculation logic here -->\n",
    "            total += len(target)\n",
    "            correct += (torch.argmax(pred, dim=1) == target).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(loader[\"test\"])\n",
    "    # <-- MODIFICATION: Calculate accuracy percentage -->\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # <-- MODIFICATION: Update print statement to include accuracy -->\n",
    "    print(f\"[Epoch {epoch + 1:3d}] Validation loss: {avg_val_loss:.3f}, Accuracy: {accuracy:.2f}%\")\n",
    "    # --- MODIFICATION: Record validation metrics at the end of the epoch ---\n",
    "    val_iter_history.append(current_iter)\n",
    "    val_loss_history.append(avg_val_loss)\n",
    "    val_acc_history.append(accuracy)\n",
    "\n",
    "print(\"Finished Training\")\n",
    "# plot train.test loss and test accuracy\n",
    "# --- New plotting code for multiple metrics on a shared axis ---\n",
    "\n",
    "# Create the main figure and the primary y-axis (for loss)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "plt.title('Training & Validation Metrics')\n",
    "\n",
    "# Plot Training Loss and Validation Loss on the left y-axis (ax1)\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss', color='tab:red')\n",
    "ax1.plot(iter_history, loss_history, color='tab:red', linestyle='--', alpha=0.7, label='Training Loss')\n",
    "ax1.plot(val_iter_history, val_loss_history, color='tab:orange', marker='o', label='Validation Loss')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "# Create the secondary y-axis (for accuracy) that shares the x-axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Accuracy (%)', color='tab:blue')\n",
    "# Plot Validation Accuracy on the right y-axis (ax2)\n",
    "ax2.plot(val_iter_history, val_acc_history, color='tab:blue', marker='s', label='Validation Accuracy')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Create a unified legend for all lines\n",
    "fig.legend(loc='upper right', bbox_to_anchor=(0.9, 0.9))\n",
    "\n",
    "# Final plot adjustments\n",
    "fig.tight_layout() # Adjust plot to prevent labels from overlapping\n",
    "plt.grid(True)\n",
    "plt.savefig('all_metrics_curve.png')\n",
    "\n",
    "print(\"\\nMetrics curve has been saved to all_metrics_curve.png\")\n",
    "\n",
    "print(\"\\nTraining loss curve has been saved to training_loss_curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for img, target in loader[\"test\"]:\n",
    "        img, target = img.to(device), target.to(device)\n",
    "        \n",
    "        # make prediction\n",
    "        pred = net(img)\n",
    "        \n",
    "        # accumulate\n",
    "        total += len(target)\n",
    "        correct += (torch.argmax(pred, dim=1) == target).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-HW-Py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
