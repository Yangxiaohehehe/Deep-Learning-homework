{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "This code baseline is inspired by and modified from [this great tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).\n",
    "\n",
    "This code can achieve an accuracy of approximately 86.50% on CIFAR-10. Please set up the environment and run your experiments starting from this baseline. You are expected to achieve an accuracy higher than this baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import some necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as tv_datasets\n",
    "import torchvision.transforms as tv_transforms\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差结构\n",
    "class Resblock(nn.Module):\n",
    "  def __init__(self,in_channel,out_channel,downsample=False):\n",
    "    super().__init__()\n",
    "    self.in_channel = in_channel\n",
    "    self.out_channel = out_channel\n",
    "    self.downsample = downsample\n",
    "    strides = 2 if self.downsample else 1\n",
    "    if self.downsample or in_channel!=out_channel:\n",
    "      self.conv3 = nn.Conv2d(in_channel,out_channel,kernel_size=1,stride=strides,padding=0,bias=False)\n",
    "\n",
    "    self.conv1 = nn.Conv2d(in_channel,out_channel,kernel_size=3,stride =strides,padding =1,bias=False)\n",
    "    self.bn1  = nn.BatchNorm2d(out_channel)\n",
    "    self.relu1 = nn.ReLU(inplace = True)\n",
    "    self.bn2  = nn.BatchNorm2d(out_channel)\n",
    "    self.conv2 = nn.Conv2d(out_channel,out_channel,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "    self.relu2 = nn.ReLU(inplace = True)\n",
    "\n",
    "  def forward(self,x):\n",
    "    identity = x\n",
    "    Y = self.relu1(self.bn1(self.conv1(x)))\n",
    "    Y = self.bn2(self.conv2(Y))\n",
    "    if self.downsample or self.in_channel!=self.out_channel:\n",
    "      identity = self.conv3(identity)\n",
    "    Y=Y+identity\n",
    "    return self.relu2(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some experimental setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_epochs = 128\n",
    "batch_size = 128\n",
    "num_workers = 2\n",
    "print_every = 200\n",
    "\n",
    "optim_name = \"Adam\"\n",
    "optim_kwargs = dict(\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-6,\n",
    ")\n",
    "\n",
    "# preprocessing pipeline for input images\n",
    "transformation = dict()\n",
    "for data_type in (\"train\", \"test\"):\n",
    "    is_train = data_type==\"train\"\n",
    "    transformation[data_type] = tv_transforms.Compose(([\n",
    "        tv_transforms.RandomRotation(degrees=15),\n",
    "        tv_transforms.RandomHorizontalFlip(),\n",
    "        tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    ] if is_train else []) + \n",
    "    [\n",
    "        tv_transforms.ToTensor(),\n",
    "        tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Image \n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torch\n",
    "\n",
    "class HuggingFaceWrapper(Dataset):\n",
    "    \"\"\"一个适配器类，使Hugging Face数据集与torchvision的(img, target)格式兼容\"\"\"\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.hf_dataset[idx]\n",
    "        \n",
    "\n",
    "        img = sample['image']\n",
    "        target = sample['label']\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "local_data_dir = \"./data\" \n",
    "\n",
    "data_files = {\n",
    "    \"train\": os.path.join(local_data_dir, \"train-00000-of-00001-1359597a978bc4fa.parquet\"),\n",
    "    \"valid\": os.path.join(local_data_dir, \"valid-00000-of-00001-1359597a978bc4fa.parquet\")\n",
    "}\n",
    "\n",
    "print(f\"正在从本地 Parquet 文件 {local_data_dir} 加载 tiny-imagenet...\")\n",
    "\n",
    "hf_datasets = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files=data_files\n",
    ")\n",
    "\n",
    "\n",
    "print(\"正在转换 'image' 列为 Image 格式...\")\n",
    "hf_datasets = hf_datasets.cast_column(\"image\", Image())\n",
    "print(\"转换完成。\")\n",
    "\n",
    "\n",
    "hf_dataset_train = hf_datasets['train']\n",
    "hf_dataset_val = hf_datasets['valid'] \n",
    "print(\"数据集加载完成。\")\n",
    "\n",
    "\n",
    "dataset, loader = {}, {}\n",
    "\n",
    "dataset[\"train\"] = HuggingFaceWrapper(hf_dataset_train, transform=transformation['train'])\n",
    "dataset[\"test\"] = HuggingFaceWrapper(hf_dataset_val, transform=transformation['test'])\n",
    "\n",
    "\n",
    "for data_type in (\"train\", \"test\"):\n",
    "    is_train = data_type==\"train\"\n",
    "    loader[data_type] = torch.utils.data.DataLoader(\n",
    "        dataset[data_type], batch_size=batch_size, shuffle=is_train, num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "print(\"DataLoader 创建完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#残差\n",
    "class CIFAR_Net_With_Resblock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # --- 1. 初始卷积和下采样部分 (对应你原来的前两个卷积块) ---\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer1 = Resblock(in_channel=64,  out_channel=128, downsample=True)\n",
    "        self.layer2 = Resblock(in_channel=128,  out_channel=128, downsample=False)\n",
    "        # 128x16x16 -> 256x8x8\n",
    "        self.layer3 = Resblock(in_channel=128, out_channel=256, downsample=True)\n",
    "        self.layer4 = Resblock(in_channel=256, out_channel=256, downsample=False)\n",
    "        # 256x8x8 -> 512x4x4\n",
    "        self.layer5 = Resblock(in_channel=256, out_channel=512, downsample=True)\n",
    "        # 为了增加网络深度，可以再加一个普通的Resblock\n",
    "        # 512x4x4 -> 512x4x4\n",
    "        self.layer6 = Resblock(in_channel=512, out_channel=512)\n",
    "\n",
    "        # --- 3. 全局池化和分类器 ---\n",
    "        self.final_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # 注意：这里的输入维度是最后一个残差块的输出通道数 (512)\n",
    "            nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.4),\n",
    "            nn.Linear(128, 200)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "\n",
    "        x = self.final_pool(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "net = CIFAR_Net_With_Resblock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# move to device\n",
    "net.to(device)\n",
    "\n",
    "# print the number of parameters\n",
    "print(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the network optimizer\n",
    "optimizer = getattr(optim, optim_name)(net.parameters(), **optim_kwargs)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_history = []\n",
    "iter_history = []\n",
    "current_iter = 0\n",
    "val_loss_history = []\n",
    "val_acc_history = []\n",
    "val_iter_history = []\n",
    "patience = 15 \n",
    "epochs_no_improve = 0 \n",
    "best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "# training loop\n",
    "net.train()\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (img, target) in enumerate(loader[\"train\"]):\n",
    "        img, target = img.to(device), target.to(device)\n",
    "\n",
    "\n",
    "        pred = net(img)\n",
    "        loss = criterion(pred, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        current_iter += 1\n",
    "        if i % print_every == print_every - 1:\n",
    "            avg_loss = running_loss / print_every\n",
    "            print(f\"[epoch={epoch + 1:3d}, iter={i + 1:5d}] loss: {running_loss / print_every:.3f}\")\n",
    "            iter_history.append(current_iter)\n",
    "            loss_history.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for img, target in loader[\"test\"]:\n",
    "            img, target = img.to(device), target.to(device)\n",
    "            pred = net(img)\n",
    "            loss = criterion(pred, target)\n",
    "            val_loss += loss.item()\n",
    "            total += len(target)\n",
    "            correct += (torch.argmax(pred, dim=1) == target).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(loader[\"test\"])\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"[Epoch {epoch + 1:3d}] Validation loss: {avg_val_loss:.3f}, Accuracy: {accuracy:.2f}%\")\n",
    "    val_iter_history.append(current_iter)\n",
    "    val_loss_history.append(avg_val_loss)\n",
    "    val_acc_history.append(accuracy)\n",
    "    # 早停\n",
    "    if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0 \n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"\\\\nEarly stopping triggered after {patience} epochs without improvement.\")\n",
    "        break \n",
    "\n",
    "\n",
    "print(\"Finished Training\")\n",
    "# 画图\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "plt.title('Training & Validation Metrics')\n",
    "\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss', color='tab:red')\n",
    "ax1.plot(iter_history, loss_history, color='tab:red', linestyle='--', alpha=0.7, label='Training Loss')\n",
    "ax1.plot(val_iter_history, val_loss_history, color='tab:orange', marker='o', label='Validation Loss')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Accuracy (%)', color='tab:blue')\n",
    "ax2.plot(val_iter_history, val_acc_history, color='tab:blue', marker='s', label='Validation Accuracy')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "fig.legend(loc='upper right', bbox_to_anchor=(0.9, 0.9))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.savefig('all_metrics_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for img, target in loader[\"test\"]:\n",
    "        img, target = img.to(device), target.to(device)\n",
    "        \n",
    "        # make prediction\n",
    "        pred = net(img)\n",
    "        \n",
    "        # accumulate\n",
    "        total += len(target)\n",
    "        correct += (torch.argmax(pred, dim=1) == target).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-HW-Py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
